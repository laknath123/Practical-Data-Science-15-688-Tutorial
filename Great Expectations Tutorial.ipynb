{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41270a64",
   "metadata": {},
   "source": [
    "## What You will Learn\n",
    "\n",
    "#### The goal of this tutorial is to introduce [Great Expectations](https://greatexpectations.io/) a python package to help ensure data quality in data science and analytics workflows. You will learn in this tutorial\n",
    "\n",
    "1.\tWhy data quality is imperative for data science.\n",
    "2.\tWhat expectations are, and how you can test expectations \n",
    "3.\tHow to set up a great expectations suite in a production environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85dec9e",
   "metadata": {},
   "source": [
    "## 1.Importance of Data Quality\n",
    "\n",
    "According to a [recent survey](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=77d4a0526f63), data scientists spend around 60 percent of their time cleaning and massaging data. And this aspect of the work is often considered not very desirable.  \n",
    "\n",
    "Data cleaning is not an aspect focused on much in coursework. In most assignments and projects, we receive already cleaned data in CSV files or access to a database and continue to build models and conduct analysis without paying too much attention to data quality issues.\n",
    "\n",
    "The data we encounter in most real-world data science projects have issues with **accuracy, completeness, uniqueness, consistency, and timeliness**. Furthermore, we may have to work with dynamic data that may get updated daily, weekly, or monthly. Consider building a machine learning model and an analytics dashboard with [311 Data from the NYC open data portal](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9). This data gets updated daily, and we have to ensure that the columns in each new update are consistent with what we already have.\n",
    "\n",
    "Most importantly, data quality can adversely impact model quality. For instance, when you are pre-processing a categorical variable to be entered into a model, an inconsistency between ***‘NYPD’ and ‘NyPD’*** would lead these two values to be considered as two distinct categories. But beyond this simple example, data quality issues can adversely impact model performance, and it may be often difficult to detect these issues during the modeling stage. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef2db8",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "in order to complete this section you need to install the **great_expectations** and **pandas** packages. Once you have succesfully installed them either using pip or anaconda, you can can import these packages using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f53bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3efc48",
   "metadata": {},
   "source": [
    "##  2.1 Quick Intro to Setting Expectations\n",
    "\n",
    "You will be working with a slightly modified version of the Titanic Dataset for this section.\n",
    "\n",
    "Let's imagine that the Titanic was able to divert its course and dodge the iceberg that stuck it in 1912 and completed its maiden voyage. Let's assume that the RMS titanic took many voyages between Europe and the UK, and a team of data engineers and data scientists with Titanics marketing division are collecting passenger data to determine which passengers it should provide premium discounts for an all-inclusive first-class pass. And during each voyage, they receive a batch of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e34046",
   "metadata": {},
   "source": [
    "Let's Load the titanic dataset from the github link with the `read_csv` function in great expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3152ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = ge.read_csv(\"https://raw.githubusercontent.com/laknath123/Practical-Data-Science-15-688-Tutorial/main/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b0e62",
   "metadata": {},
   "source": [
    "Lets Explore the first few lines of this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b210829",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e067dd",
   "metadata": {},
   "source": [
    "In This tutorial, we hope to make some modifications to the original dataset.\n",
    "-  First we we will remove the `Survived` Column\n",
    "-  Next we will split this dataset into two batches\n",
    "-  Create A data anamoloy by Adding the Value `Z` to the `Embarked` column and rename the `SibSp`column as `SIBSP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f50cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_df = titanic.loc[:,titanic.columns !='Survived']\n",
    "df_batch1= titanic_df[0:400]\n",
    "df_batch2= titanic_df[400:]\n",
    "df_batch2.loc[400,'Embarked']='Z' # Set an Anomolous value\n",
    "df_batch2 = df_batch2.rename(columns={'SibSp':'SIBSP'}) # Rename the column to create a column name mismatch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e4971",
   "metadata": {},
   "source": [
    "## 2.2 Setting Table Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1978470",
   "metadata": {},
   "source": [
    "Table Expectations are all about standardizing the structure of your data frames. If you have worked with multiple datasets, One of the common issues you run into is errors when appending and merging two data frames. These issues are often caused by\n",
    "- Not having the correct number of columns\n",
    "- A mismatch between column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11338a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_batch1,df_batch2]\n",
    "pd.concat(frames).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805264d",
   "metadata": {},
   "source": [
    "As you can see from the above output, when we tried to concatnate the dataframes it created a new column called `SIBSP` due to the column name mismatch. Let's look at how we can leverage great expectations to detect this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9bb5c",
   "metadata": {},
   "source": [
    "We know that the df_batch1 dataset had the following list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016991b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_batch1.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75c298",
   "metadata": {},
   "source": [
    "We can use this list and check if df_batch2 dataframe match columns in the original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a29d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_batch2.expect_table_columns_to_match_ordered_list(column_list=df_batch1.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4232e99c",
   "metadata": {},
   "source": [
    "When you run an expectation on a dataset it returns a result like the one you see above. The most important item to look at is the success parameter. Here it is evident that `success: False` meaning that we have failed an expectation. But what's really cool is that it shows you exactly where the mismatch happened. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce1bdd7",
   "metadata": {},
   "source": [
    "Here are a some other table expectations you should explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0bd88c",
   "metadata": {},
   "source": [
    "#### Create an Expectation on the number of rows for each of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02559b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "since it returns a dictionary object, you can simply look at the 'success' key\n",
    "You can pass in a min and max value parameter on what you expect the minimum and maximum row counts to be\n",
    "'''\n",
    "df_batch1.expect_table_row_count_to_be_between(min_value=350,max_value=450)['success']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f34df6",
   "metadata": {},
   "source": [
    "#### Create an Expectation to check whether a specific column exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe719b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We Want to make sure the Embarked column exists since we will use it in the next section\n",
    "'''\n",
    "df_batch1.expect_column_to_exist(column='Embarked')['success']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0074c",
   "metadata": {},
   "source": [
    "#### Test the Column count for tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_batch2.expect_table_column_count_to_equal(11)['success'])\n",
    "print(df_batch2.expect_table_column_count_to_equal(11)['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285e4a6",
   "metadata": {},
   "source": [
    "## 2.2 Setting Expectations on Categorical Values and Exploring your Expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a315a2",
   "metadata": {},
   "source": [
    "While table expectations are important to detect issues in tables and data frames, most data quality issues arise in the actual data contained within these tables itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89925c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_batch1.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95ccd6",
   "metadata": {},
   "source": [
    "The data team knows that passengers get on board the ship from one of 3 ports. Cherbourg in France, Queenstown in Ireland, and Southhampton in the UK. If you look at the Embarked column, these ports are categorized as Cherbourg- `C`, Queenstown- `Q`, Southhampton-`S`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30c6eb",
   "metadata": {},
   "source": [
    "We can use the great expectations package to create an expectation that the Embarked column should only contain these three values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1.expect_column_values_to_be_in_set('Embarked',['S','C','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d260cf",
   "metadata": {},
   "source": [
    "Anytime you create an expectation,that expectation is stored as a config, and we can look at the config object it creates using the `get_expectation_suite()` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ba20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de94f4",
   "metadata": {},
   "source": [
    "Since we hope to use this config to validate the data we recieve in the future, Let's save the previous expectation we created as `titanic_config` in our workspace using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_config = df_batch1.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8dab93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can explore the list of the expectations that you have already created using the following command\n",
    "titanic_config['expectations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670a528",
   "metadata": {},
   "source": [
    "Once the Data Team receives another batch of passenger data from a voyage, they can use the config they had created earlier to validate the new data.\n",
    "You have to load the new batch of data and then run the validate command and pass the titanic config you created earlier as a parameter.\n",
    "Load the second batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2 = df_batch2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a25ba9",
   "metadata": {},
   "source": [
    "you can now validate this second batch of data, and also pass in a parameter called `only_return_failures=True` to specifically show the validation rules that have failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b5954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch2.validate(expectation_suite= titanic_config,only_return_failures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d6b83",
   "metadata": {},
   "source": [
    "If we look at the results key in the above output, It is evident now that we have failed our expectation since `\"success\": false`. \n",
    "It is also clear from this output that this expectation failed, because there was an unexpected value `Z` in the `Embarked` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19e20b",
   "metadata": {},
   "source": [
    "In instances where you are dealing with data that gets updated hourly, daily, weekly etc. You may want to keep track of each of your validations runs. And you you can get this information, using the following command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2.validate(expectation_suite= titanic_config)['meta']['run_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c4b0d",
   "metadata": {},
   "source": [
    "## 2.2 Expectations Around Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730f544",
   "metadata": {},
   "source": [
    "Null values in your dataset are inevitable. In most cases, you would want to ensure that certain columns don't contain any null values. For instance, if you were hoping to use the `PassengerId` column as the Primary Key in a database table, you would want to ensure that this column is free of null values. \n",
    "\n",
    "Let's create an expectation to tackle this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3dc47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expect= df_batch1.expect_column_values_to_not_be_null('PassengerId')\n",
    "print(expect['result'])\n",
    "print(expect['success'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ede36",
   "metadata": {},
   "source": [
    "Sometimes though, you will encounter null values, but you want to ensure that you set a bound on the percentage of null values that you would tolerate. \n",
    "\n",
    "Let's look at the percentage of null values in our first batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1['Cabin'].isna().sum()\n",
    "df_batch1['Cabin'].isna().sum()/len(df_batch1['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a4e4b",
   "metadata": {},
   "source": [
    "Based on this observation we can set an expectation that we will tolerate around 70 percent of null values in this column. The code chunk below shows that we passed the test, and that approximately 23 percent of the values in this column were null in the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_batch2.expect_column_values_to_be_null('Cabin',0.7)['success'])\n",
    "df_batch2.expect_column_values_to_be_null('Cabin',0.7)['result']['unexpected_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch2['Cabin'].isna().sum()/len(df_batch2['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23b480",
   "metadata": {},
   "source": [
    "## 2.4 Setting Statistical Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44906c",
   "metadata": {},
   "source": [
    "The great expectation package also provides ways to build expectations related to statistics from our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278cc5d",
   "metadata": {},
   "source": [
    "Let's look at the average fare that that we charged passengers during the first voyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch1['Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c6a65",
   "metadata": {},
   "source": [
    "Certain industries and organizations have [Average Cost Pricing Rules](https://www.investopedia.com/terms/a/average_cost_pricing_rule.asp) or internal policies that require them to set prices within a certain range. Let's assume that the Titanic's pricing team has determined that they want the Average Fare to fall between a confidence interval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffedf21",
   "metadata": {},
   "source": [
    "Let's calculate a 95 percent confidence interval for the average fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ab432",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_b, upper_b = st.norm.interval(alpha=0.95, loc=np.mean(df_batch1['Fare']), scale=st.sem(df_batch1['Fare']))\n",
    "print(lower_b)\n",
    "print(upper_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748374a",
   "metadata": {},
   "source": [
    "We can set an expectation to test this using the `expect_column_mean_to_be_between` method and run this expectation on our second batch of data with the upper and lower bounds we calculated in the earlier step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caef14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_batch2.expect_column_mean_to_be_between('Fare',lower_b,upper_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40049b88",
   "metadata": {},
   "source": [
    "When we run this expectation on our second batch of data, it is evident that the average fare falls within the expected range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dda90d",
   "metadata": {},
   "source": [
    "We can also set an expectation for the median value of columns and provide a range of values that we would tolerate. \n",
    "We can use expectations to identify outliers that fall outside of the  interquartile range or outside the 25th and 75th percentiles of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40408bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_batch1['Fare'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perce_25th = np.percentile(df_batch1['Fare'],25)\n",
    "perce_75th = np.percentile(df_batch1['Fare'],75)\n",
    "print(\"25th percentile of the dataset is \",perce_25th)\n",
    "print(\"75th percentile of the dataset is \",perce_75th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dff364",
   "metadata": {},
   "source": [
    "Let's set an expectation to see if any of the subsequent batches of data have a median value that is outside of this range for the `Fare` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36093481",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_batch2.expect_column_median_to_be_between('Fare',perce_25th,perce_75th)['result'])\n",
    "print(df_batch2.expect_column_median_to_be_between('Fare',perce_25th,perce_75th)['success'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc210d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204e303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a3c2504",
   "metadata": {},
   "source": [
    "## 3.0 Setting up an Expectation Suite for the Yelp Api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fd98c",
   "metadata": {},
   "source": [
    "Let's put everything that we learned so far together and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b894db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf944957",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = response.json()\n",
    "data_source= pd.json_normalize(data_dict['businesses'])\n",
    "data_source.head()\n",
    "data_source.to_csv('yelp_batch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76287db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e8794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a79e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1358a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4eeaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ge.read_csv('yelp_batch.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c87d9c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db41a830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>alias</th>\n",
       "      <th>name</th>\n",
       "      <th>image_url</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>url</th>\n",
       "      <th>review_count</th>\n",
       "      <th>categories</th>\n",
       "      <th>rating</th>\n",
       "      <th>...</th>\n",
       "      <th>coordinates.latitude</th>\n",
       "      <th>coordinates.longitude</th>\n",
       "      <th>location.address1</th>\n",
       "      <th>location.address2</th>\n",
       "      <th>location.address3</th>\n",
       "      <th>location.city</th>\n",
       "      <th>location.zip_code</th>\n",
       "      <th>location.country</th>\n",
       "      <th>location.state</th>\n",
       "      <th>location.display_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>L4r6klm7FG4QBbNe8gu5-A</td>\n",
       "      <td>commonplace-coffee-pittsburgh-3</td>\n",
       "      <td>Commonplace Coffee</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/5TYkkK...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.yelp.com/biz/commonplace-coffee-pi...</td>\n",
       "      <td>207</td>\n",
       "      <td>[{'alias': 'coffee', 'title': 'Coffee &amp; Tea'},...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>40.438236</td>\n",
       "      <td>-79.926516</td>\n",
       "      <td>5827 Forbes Ave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>15217</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>['5827 Forbes Ave', 'Pittsburgh, PA 15217']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DPR86ATfmOo3s9kDhQrzzA</td>\n",
       "      <td>round-table-coffee-pittsburgh</td>\n",
       "      <td>Round Table Coffee</td>\n",
       "      <td>https://s3-media1.fl.yelpcdn.com/bphoto/e8-XBa...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.yelp.com/biz/round-table-coffee-pi...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'alias': 'coffee', 'title': 'Coffee &amp; Tea'}]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.456334</td>\n",
       "      <td>-79.930275</td>\n",
       "      <td>5830 Ellsworth Ave</td>\n",
       "      <td>Ste 100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>15232</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>['5830 Ellsworth Ave', 'Ste 100', 'Pittsburgh,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      id                            alias  \\\n",
       "0           0  L4r6klm7FG4QBbNe8gu5-A  commonplace-coffee-pittsburgh-3   \n",
       "1           1  DPR86ATfmOo3s9kDhQrzzA    round-table-coffee-pittsburgh   \n",
       "\n",
       "                 name                                          image_url  \\\n",
       "0  Commonplace Coffee  https://s3-media2.fl.yelpcdn.com/bphoto/5TYkkK...   \n",
       "1  Round Table Coffee  https://s3-media1.fl.yelpcdn.com/bphoto/e8-XBa...   \n",
       "\n",
       "   is_closed                                                url  review_count  \\\n",
       "0      False  https://www.yelp.com/biz/commonplace-coffee-pi...           207   \n",
       "1      False  https://www.yelp.com/biz/round-table-coffee-pi...            16   \n",
       "\n",
       "                                          categories  rating  ...  \\\n",
       "0  [{'alias': 'coffee', 'title': 'Coffee & Tea'},...     4.5  ...   \n",
       "1     [{'alias': 'coffee', 'title': 'Coffee & Tea'}]     5.0  ...   \n",
       "\n",
       "  coordinates.latitude coordinates.longitude   location.address1  \\\n",
       "0            40.438236            -79.926516     5827 Forbes Ave   \n",
       "1            40.456334            -79.930275  5830 Ellsworth Ave   \n",
       "\n",
       "  location.address2  location.address3  location.city  location.zip_code  \\\n",
       "0               NaN                NaN     Pittsburgh              15217   \n",
       "1           Ste 100                NaN     Pittsburgh              15232   \n",
       "\n",
       "  location.country location.state  \\\n",
       "0               US             PA   \n",
       "1               US             PA   \n",
       "\n",
       "                            location.display_address  \n",
       "0        ['5827 Forbes Ave', 'Pittsburgh, PA 15217']  \n",
       "1  ['5830 Ellsworth Ave', 'Ste 100', 'Pittsburgh,...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0e829d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(batch.is_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b7dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e24c7a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.96446788208796\n",
      "109.15553211791205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"meta\": {},\n",
       "  \"success\": true,\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"result\": {\n",
       "    \"observed_value\": 85.06,\n",
       "    \"element_count\": 50,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columm_list = batch.columns.tolist()\n",
    "# Lets set the following expectations\n",
    "batch.expect_table_columns_to_match_ordered_list(columm_list)\n",
    "batch.expect_column_values_to_not_be_null('id')\n",
    "batch.expect_column_max_to_be_between('rating',5.0)\n",
    "batch.expect_column_mean_to_be_between('rating',4.4,5.0) # Average coffee shop rating to be between 4.0 and 5.0\n",
    "lower_b, upper_b = st.norm.interval(alpha=0.95, loc=np.mean(batch['review_count']), scale=st.sem(batch['review_count']))\n",
    "print(lower_b)\n",
    "print(upper_b)\n",
    "batch.expect_column_mean_to_be_between('review_count',lower_b,upper_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a302400",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_config = batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab7c9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_config['expectation_suite_name'] = 'yelp_expectations'\n",
    "yelp_config['data_asset_type']='pandas dataframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509d05d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.14.10\"\n",
       "  },\n",
       "  \"expectation_suite_name\": \"yelp_expectations\",\n",
       "  \"data_asset_type\": \"pandas dataframe\",\n",
       "  \"ge_cloud_id\": null,\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"kwargs\": {\n",
       "        \"column_list\": [\n",
       "          \"Unnamed: 0\",\n",
       "          \"id\",\n",
       "          \"alias\",\n",
       "          \"name\",\n",
       "          \"image_url\",\n",
       "          \"is_closed\",\n",
       "          \"url\",\n",
       "          \"review_count\",\n",
       "          \"categories\",\n",
       "          \"rating\",\n",
       "          \"transactions\",\n",
       "          \"price\",\n",
       "          \"phone\",\n",
       "          \"display_phone\",\n",
       "          \"distance\",\n",
       "          \"coordinates.latitude\",\n",
       "          \"coordinates.longitude\",\n",
       "          \"location.address1\",\n",
       "          \"location.address2\",\n",
       "          \"location.address3\",\n",
       "          \"location.city\",\n",
       "          \"location.zip_code\",\n",
       "          \"location.country\",\n",
       "          \"location.state\",\n",
       "          \"location.display_address\"\n",
       "        ]\n",
       "      },\n",
       "      \"expectation_type\": \"expect_table_columns_to_match_ordered_list\"\n",
       "    },\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"id\"\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_values_to_not_be_null\"\n",
       "    },\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"rating\",\n",
       "        \"min_value\": 5.0\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_max_to_be_between\"\n",
       "    },\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"rating\",\n",
       "        \"min_value\": 4.4,\n",
       "        \"max_value\": 5.0\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_mean_to_be_between\"\n",
       "    },\n",
       "    {\n",
       "      \"meta\": {},\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"review_count\",\n",
       "        \"min_value\": 60.96446788208796,\n",
       "        \"max_value\": 109.15553211791205\n",
       "      },\n",
       "      \"expectation_type\": \"expect_column_mean_to_be_between\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b94f39a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6d07322",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'yFPQl70OTPmsWvi2XU5lgIeMUVfKGrMx7Jj5lPnvxgX_DJLoX4tRfIct7GgALvkgvFNeMOhrHTU0v5p4pvRH2qgWu8IkhaRZQ68LdjVmK9jh4sPdpR_NU0xA_0X5YXYx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04fbeb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(term, location):\n",
    "    headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "    search_api_url = 'https://api.yelp.com/v3/businesses/search'\n",
    "    params = {'term': term, \n",
    "          'location': location,\n",
    "          'limit': 50}\n",
    "    response = requests.get(search_api_url, headers=headers, params=params, timeout=5)\n",
    "    data_dict = response.json()\n",
    "    data_source= pd.json_normalize(data_dict['businesses'])\n",
    "    data_source.head()\n",
    "    data_source.to_csv('newbatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "448ef357",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_request('coffee','Shadyside, Pittsburgh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0db098c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch = ge.read_csv('newbatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b8bed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = new_batch.validate(expectation_suite= yelp_config,only_return_failures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5a174e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluated_expectations': 5,\n",
       " 'successful_expectations': 3,\n",
       " 'unsuccessful_expectations': 2,\n",
       " 'success_percent': 60.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation['statistics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e2968",
   "metadata": {},
   "source": [
    "## 2.4 Explore The World of Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ed6b3",
   "metadata": {},
   "source": [
    "We just scratched the surface of what great expectations have to offer in the previous section. \n",
    "The great expectations library has a host of tests to check issues with your data. These test include ways to evaluate statistical expectations, expectations related to regular expressions, and ones to deal with geospatial such as setting latitude and longitude values to be within a certain range.\n",
    "\n",
    "You can check out the entire list of expectations available using the this [link](https://greatexpectations.io/expectations)\n",
    "\n",
    "Since Great Expectations is an open-source package, the community can contribute new expectations, and according to the website the goal of this package is create a **SHARED, OPEN STANDARD OF DATA QUALITY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb8faf",
   "metadata": {},
   "source": [
    "### 3.0 Setting up a Great Expectation suite in a production environment (Optional Section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051672a8",
   "metadata": {},
   "source": [
    "The data science workflow in a typical organization involves obtaining data from many sources. For instance, the data may come from enterprise resource planning systems, customer relationship management systems, or from sensors.\n",
    "\n",
    "In an analytics workflow that spans multiple teams, data engineering teams create pipelines to move data and may create databases and data warehouses to store data. These pipelines would then be used by data analysts/ business intelligence developers to create dashboards, and data scientists to build and deploy machine learning models.\n",
    " \n",
    "Great Expectations seems to be a popular technology  currently being used by data engineers and data science teams to run data quality tests before  ingesting data into databases and models\n",
    "\n",
    "- [How Great Expectations is used by the Global Analytics Team at Heineken](https://greatexpectations.io/case-studies/heineken-case-study/)\n",
    "\n",
    " \n",
    "In this section, I guide you through how great_expectations may be deployed in a typical data science workflow where you have to deal with dynamic data inflows as opposed to dealing with a CSV file at a time.\n",
    " \n",
    "Again, a real-world workflow may be a lot more involved than what I present here, but I hope that this gives you a general idea\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78c034",
   "metadata": {},
   "source": [
    "## Set up\n",
    "1.\tDownload the zipfile or obtain it from github, and save it somewhere in your machine.\n",
    "2.\tOpen the anaconda prompt or terminal and use `cd` to go to the directory where the file is saved\n",
    "3.\tonce you have cd’d into that folder. Create a virtual environment with the following command `python -m venv venv`\n",
    "4.\tActivate this virtual environment by running `venv\\Scripts\\activate.bat`\n",
    "5.\tOnce you have activated the virtual environment run. \n",
    "    \n",
    "    -`pip install great_expectations`  \n",
    "    -`pip install sqlalchemy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11943d3",
   "metadata": {},
   "source": [
    "## 3.1 Launch and initialize Great Expectations\n",
    " \n",
    "Run the following command\n",
    "\n",
    "`Great_expectations init`\n",
    "\n",
    "The command above initializes Great Expectations in your folder, and if you look at the folder, you should be able to see that you have a new folder named great_expectations, and it has the structure described in the following image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27638b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acb003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177782d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
